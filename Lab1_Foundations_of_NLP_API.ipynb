{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d5b477d",
      "metadata": {
        "id": "2d5b477d"
      },
      "source": [
        "# Lab 1: Foundations of NLP\n",
        "\n",
        "In this lab you will **choose one** API to fetch approximately 200 words of live text, then use that text for all tasks below.\n",
        "\n",
        "**TODO:** Pick your API from the list (see README/API docs), and implement the fetch in the first code cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "API_KEY = \"0ef21751a05b4363ae839ef0d77266a1\"\n",
        "url = f'https://newsapi.org/v2/everything?q=Miami&apiKey={API_KEY}'\n",
        "\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    print(\"Status Code:\", response.status_code)\n",
        "    print(\"Response Keys\", data.keys())\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"API Error:\", data.get('message', 'Unknown error'))\n",
        "    elif 'articles' not in data:\n",
        "        print(\"Invalid response format. Available keys:\", data.keys())\n",
        "    else:\n",
        "        articles = data['articles']\n",
        "        raw_text = ' '.join([\n",
        "            a['title'] + ' ' + (a.get('description', '') or '')\n",
        "            for a in articles[:22]\n",
        "        ])[:777]\n",
        "\n",
        "        print(\"Success! Text sample:\", raw_text[:222] + \"...\")\n",
        "        print(f\"Word count: {len(raw_text.split())}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Failed with error: {str(e)}\")\n",
        "    # Fallback Point\n",
        "    raw_text = \"\"\"Miami is a major city in Florida known for its beaches...\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zT6JvMHehoH",
        "outputId": "7c63dfcb-0492-4a51-e3e8-9b21f0a89332"
      },
      "id": "4zT6JvMHehoH",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Response Keys dict_keys(['status', 'totalResults', 'articles'])\n",
            "Success! Text sample: Olympic 100m medallist Kerley arrested in Miami Two-time Olympic 100m medallist Fred Kerley is arrested in Miami for allegedly punching former partner Alaysha Johnson, according to police. Formula 1 Drivers Just Hit the Tr...\n",
            "Word count: 129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ace0325",
      "metadata": {
        "id": "3ace0325"
      },
      "source": [
        "## 1. Text Preprocessing (30 pts)\n",
        "\n",
        "- Use the `raw_text` variable you fetched.\n",
        "- Tokenize, lowercase, remove punctuation.\n",
        "- Remove stopwords.\n",
        "- Plot the top-10 most frequent tokens.\n",
        "\n",
        "**TODO:** Write your code below and commit after each sub-step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e0a08365",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0a08365",
        "outputId": "3d32c46a-6ec9-458b-d3f7-85866b35dc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['olympic', '100m', 'medallist', 'kerley', 'arrested', 'in', 'miami', 'two-time', 'olympic', '100m', 'medallist', 'fred', 'kerley', 'is', 'arrested', 'in', 'miami', 'for', 'allegedly', 'punching']\n",
            "\n",
            "Total tokens: 134\n"
          ]
        }
      ],
      "source": [
        "# TODO: Tokenize and clean raw_text\n",
        "tokens = word_tokenize(raw_text.lower())\n",
        "tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "print(tokens[:20])\n",
        "print(f\"\\nTotal tokens: {len(tokens)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "72aad684",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72aad684",
        "outputId": "216733fb-4982-4e0c-8a70-bb86ec3869c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['olympic', '100m', 'medallist', 'kerley', 'arrested', 'miami', 'two-time', 'olympic', '100m', 'medallist', 'fred', 'kerley', 'arrested', 'miami', 'allegedly', 'punching', 'former', 'partner', 'alaysha', 'johnson']\n",
            "\n",
            " Tokens left: 94\n"
          ]
        }
      ],
      "source": [
        "# TODO: Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "print(filtered_tokens[:20])\n",
        "print(f\"\\n Tokens left: {len(filtered_tokens)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "719f9ddf",
      "metadata": {
        "id": "719f9ddf"
      },
      "outputs": [],
      "source": [
        "# TODO: Plot frequent tokens\n",
        "word_counts = Counter(filtered_tokens)\n",
        "top_10 = word_counts.most_common(10)\n",
        "\n",
        "words = [item[0] for item in top_10]\n",
        "counts = [item[1] for item in top_10]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(words, counts, color = 'orange')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 10 Most Frequent Words')\n",
        "plt.xticks(rotation=45, ha = 'right', fontsize = 10)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save & Show\n",
        "plt.savefig('word_frequencies.png')\n",
        "plt.show()\n",
        "\n",
        "# Print repeated words\n",
        "print(\"\\nTop 10 words:\")\n",
        "for word, count in top_10:\n",
        "    print(f\"{word}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6afbb41",
      "metadata": {
        "id": "c6afbb41"
      },
      "source": [
        "## 2. Synonym Generation (30 pts)\n",
        "\n",
        "- Pick 5 tokens from your preprocessed results.\n",
        "- Manually list 2-3 synonyms each.\n",
        "- Use Google AI Studio Text API to generate synonyms for each.\n",
        "\n",
        "**TODO:** Complete the code and reflections."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMF6WFsGu1An"
      },
      "id": "rMF6WFsGu1An",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: using my key \"AIzaSyC7SJ9_eGhYqgUtHd2D9yHOX-86CBiDd9M\", Pick 5 tokens from your preprocessed results.\n",
        "# Manually list 2-3 synonyms each.\n",
        "# Use Google AI Studio Text API to generate synonyms for each\n",
        "\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Assuming 'AIzaSyC7SJ9_eGhYqgUtHd2D9yHOX-86CBiDd9M' is the actual API key value you intend to use.\n",
        "# If the key is stored as a secret in Colab, use `userdata.get('YOUR_SECRET_NAME')` instead.\n",
        "# In this case, the user provided the key directly in the prompt, so we use that.\n",
        "API_KEY = \"AIzaSyC7SJ9_eGhYqgUtHd2D9yHOX-86CBiDd9M\"\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Pick 5 tokens from the preprocessed results (filtered_tokens)\n",
        "selected_tokens = filtered_tokens[:5] # Taking the first 5 for demonstration\n",
        "\n",
        "print(\"Selected Tokens for Synonym Generation:\", selected_tokens)\n",
        "\n",
        "# Manually list synonyms (example based on potential common words)\n",
        "manual_synonyms = {\n",
        "    'miami': ['south beach', 'magic city'],\n",
        "    'florida': ['sunshine state'],\n",
        "    'city': ['metropolis', 'town', 'urban center'],\n",
        "    'major': ['important', 'significant', 'principal'],\n",
        "    'known': ['famous', 'recognized', 'celebrated']\n",
        "}\n",
        "\n",
        "print(\"\\nManually Listed Synonyms:\")\n",
        "for token, synonyms in manual_synonyms.items():\n",
        "  print(f\"{token}: {', '.join(synonyms)}\")\n",
        "\n",
        "\n",
        "# Use Google AI Studio Text API to generate synonyms\n",
        "model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "print(\"\\nAI Generated Synonyms:\")\n",
        "for token in selected_tokens:\n",
        "  try:\n",
        "    prompt = f\"List 3 synonyms for the word '{token}'.\"\n",
        "    response = model.generate_content(prompt)\n",
        "    print(f\"{token}: {response.text.strip()}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Could not generate synonyms for '{token}': {e}\")"
      ],
      "metadata": {
        "id": "JFMY9KsBurmk",
        "outputId": "98114673-de1b-4f77-e6ee-52787ce8e015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "id": "JFMY9KsBurmk",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Tokens for Synonym Generation: ['olympic', '100m', 'medallist', 'kerley', 'arrested']\n",
            "\n",
            "Manually Listed Synonyms:\n",
            "miami: south beach, magic city\n",
            "florida: sunshine state\n",
            "city: metropolis, town, urban center\n",
            "major: important, significant, principal\n",
            "known: famous, recognized, celebrated\n",
            "\n",
            "AI Generated Synonyms:\n",
            "olympic: 1. Games\n",
            "2. Olympian (referring to the athletes or the event itself)\n",
            "3. International (emphasizing the global nature of the event)\n",
            "100m: * **One hundred meters**\n",
            "* **A hundred meters**\n",
            "* **100 metres** (Note the British spelling)\n",
            "medallist: 1. Award winner\n",
            "2. Prize winner\n",
            "3. Champion\n",
            "kerley: There are no common synonyms for \"Kerley\" as it's primarily a surname and a less common given name.  There's no inherent meaning that readily lends itself to interchangeable words.\n",
            "arrested: 1. Apprehended\n",
            "2. Detained\n",
            "3. Taken into custody\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "nBuY1JkFukvy"
      },
      "id": "nBuY1JkFukvy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "cbe374bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbe374bd",
        "outputId": "1bf25370-32d9-47d3-98cd-672141575121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected words for synonym generation: ['allegedly', 'faire', 'build', 'silver', 'arrested']\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import aiplatform\n",
        "import random\n",
        "\n",
        "selected_words = random.sample([w for w in set(filtered_tokens) if len(w) > 4], 5)\n",
        "print(\"Selected words for synonym generation:\", selected_words)\n",
        "\n",
        "# Manual synonyms (5 pts)\n",
        "manual_synonyms = {\n",
        "    'miami': ['city', 'metropolis', 'urban area'],\n",
        "    'allegedly': ['reportedly', 'likely', 'reputedly'],\n",
        "    'punching': ['slapping', 'knocking', 'hitting'],\n",
        "    'former': ['old', 'once', 'sometime'],\n",
        "    'partner': ['wife', 'husband', 'spouse']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "67852b47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "67852b47",
        "outputId": "b21522d9-1662-41a2-c3df-be270f7fd116"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-59-b1c42ccf3abd>, line 34)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-b1c42ccf3abd>\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "# TODO: Call Google AI Studio Text API for synonyms\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyC7SJ9_eGhYqgUtHd2D9yHOX-86CBiDd9M\")\n",
        "\n",
        "def generate_synonyms(word):\n",
        "    prompt = f\"Generate 3 professional synonyms for '{word}' as comma-separated values. Only return the words.\"\n",
        "# TODO: Call Google AI Studio Text API for synonyms\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyC7SJ9_eGhYqgUtHd2D9yHOX-86CBiDd9M\")\n",
        "\n",
        "def generate_synonyms(word):\n",
        "    prompt = f\"Generate 3 professional synonyms for '{word}' as comma-separated values. Only return the words.\"\n",
        "    try:\n",
        "        response = genai.generate_text(\n",
        "            model='models/gemini-2.0-flash',\n",
        "            prompt=prompt,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return [s.strip() for s in response.result.split(',')[:3]]\n",
        "    except Exception as e:\n",
        "        print(f\"AI Error for {word}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Generate and compare synonyms\n",
        "print(\"\\n{:15} | {:40} | {}\".format(\"Word\", \"Manual Synonyms\", \"AI Synonyms\"))\n",
        "print(\"-\"*80)\n",
        "for word in selected_words:\n",
        "    ai_syns = generate_synonyms(word)\n",
        "    print(\"{:15} | {:40} | {}\".format(\n",
        "        word,\n",
        "        ', '.join(manual_synonyms.get(word, ['N/A'])),\n",
        "        ', '.join(ai_syns) if ai_syns else 'API Error'\n",
        "    ))\n",
        "        )\n",
        "        return [s.strip() for s in response.result.split(',')[:3]]\n",
        "    except Exception as e:\n",
        "        print(f\"AI Error for {word}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Generate and compare synonyms\n",
        "print(\"\\n{:15} | {:40} | {}\".format(\"Word\", \"Manual Synonyms\", \"AI Synonyms\"))\n",
        "print(\"-\"*80)\n",
        "for word in selected_words:\n",
        "    ai_syns = generate_synonyms(word)\n",
        "    print(\"{:15} | {:40} | {}\".format(\n",
        "        word,\n",
        "        ', '.join(manual_synonyms.get(word, ['N/A'])),\n",
        "        ', '.join(ai_syns) if ai_syns else 'API Error'\n",
        "    ))"
      ]
    },
    {
      "source": [
        "# TODO: Call Google AI Studio Text API for synonyms\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyC7SJ9_eGhYqgUtHd2D9yHOX-86CBiDd9M\")\n",
        "\n",
        "def generate_synonyms(word):\n",
        "    prompt = f\"Generate 3 professional synonyms for '{word}' as comma-separated values. Only return the words.\"\n",
        "    try:\n",
        "        response = genai.generate_text(\n",
        "            model='models/gemini-2.0-flash',\n",
        "            prompt=prompt,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return [s.strip() for s in response.result.split(',')[:3]]\n",
        "    except Exception as e:\n",
        "        print(f\"AI Error for {word}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Generate and compare synonyms\n",
        "print(\"\\n{:15} | {:40} | {}\".format(\"Word\", \"Manual Synonyms\", \"AI Synonyms\"))\n",
        "print(\"-\"*80)\n",
        "for word in selected_words:\n",
        "    ai_syns = generate_synonyms(word)\n",
        "    print(\"{:15} | {:40} | {}\".format(\n",
        "        word,\n",
        "        ', '.join(manual_synonyms.get(word, ['N/A'])),\n",
        "        ', '.join(ai_syns) if ai_syns else 'API Error'\n",
        "    ))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7oxPl_r0uail",
        "outputId": "99901985-85b7-4c9d-d0c0-783d729bbb09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7oxPl_r0uail",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word            | Manual Synonyms                          | AI Synonyms\n",
            "--------------------------------------------------------------------------------\n",
            "AI Error for allegedly: module 'google.generativeai' has no attribute 'generate_text'\n",
            "allegedly       | reportedly, likely, reputedly            | API Error\n",
            "AI Error for faire: module 'google.generativeai' has no attribute 'generate_text'\n",
            "faire           | N/A                                      | API Error\n",
            "AI Error for build: module 'google.generativeai' has no attribute 'generate_text'\n",
            "build           | N/A                                      | API Error\n",
            "AI Error for silver: module 'google.generativeai' has no attribute 'generate_text'\n",
            "silver          | N/A                                      | API Error\n",
            "AI Error for arrested: module 'google.generativeai' has no attribute 'generate_text'\n",
            "arrested        | N/A                                      | API Error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ee1a81",
      "metadata": {
        "id": "a7ee1a81"
      },
      "source": [
        "## 3. Part-of-Speech Annotation (20 pts)\n",
        "\n",
        "- Select one sentence from `raw_text`.\n",
        "- Manually tag each word with its POS.\n",
        "- Call the AI Studio syntax endpoint and compare.\n",
        "\n",
        "**TODO:** Implement tagging and comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b2cab55",
      "metadata": {
        "id": "5b2cab55"
      },
      "outputs": [],
      "source": [
        "# TODO: Manual POS tagging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b000fc",
      "metadata": {
        "id": "b5b000fc"
      },
      "outputs": [],
      "source": [
        "# TODO: Call AI Studio syntax endpoint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd782a6",
      "metadata": {
        "id": "9bd782a6"
      },
      "source": [
        "## 4. Thinking & Reflection (20 pts)\n",
        "\n",
        "Answer in Markdown:\n",
        "1. Which preprocessing step had the biggest impact?\n",
        "2. What surprised you about the AI outputs?\n",
        "3. How would you integrate manual rules and AI calls in a production pipeline?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}